"""
Dead Letter Queue ìž¬ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸
ì‹¤íŒ¨í•œ ë°ì´í„°ë“¤ì„ ë‹¤ì‹œ ì²˜ë¦¬ ì‹œë„

ì‚¬ìš©ë²•:
  python process_dead_letters.py                    # ëª¨ë“  ì‹¤íŒ¨ ë°ì´í„° ìž¬ì²˜ë¦¬
  python process_dead_letters.py crawler 20240122   # íŠ¹ì • ë‚ ì§œ í¬ë¡¤ëŸ¬ ì‹¤íŒ¨ ìž¬ì²˜ë¦¬  
  python process_dead_letters.py vector 20240122    # íŠ¹ì • ë‚ ì§œ ë²¡í„° ì‹¤íŒ¨ ìž¬ì²˜ë¦¬
"""

import asyncio
from datetime import datetime
import json
from pathlib import Path
import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent))

from data_crawler import BackroomCrawler, EscapeRoomData
from vector_generator import VectorGenerator


class DeadLetterProcessor:
    """Dead Letter Queue ìž¬ì²˜ë¦¬ê¸°"""
    
    def __init__(self):
        self.dlq_dir = Path("data/dead_letters")
        self.success_count = 0
        self.failure_count = 0
        
    async def process_all_dead_letters(self):
        """ëª¨ë“  Dead Letter íŒŒì¼ ìž¬ì²˜ë¦¬"""
        if not self.dlq_dir.exists():
            print("ðŸ“­ Dead Letter ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
            
        dlq_files = list(self.dlq_dir.glob("*.jsonl"))
        if not dlq_files:
            print("ðŸ“­ ì²˜ë¦¬í•  Dead Letter íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
            
        print(f"ðŸ“‹ ë°œê²¬ëœ Dead Letter íŒŒì¼: {len(dlq_files)}ê°œ")
        
        for dlq_file in dlq_files:
            print(f"\nðŸ”„ ì²˜ë¦¬ ì¤‘: {dlq_file.name}")
            
            if "crawler_failures" in dlq_file.name:
                await self._process_crawler_failures(dlq_file)
            elif "vector_failures" in dlq_file.name:
                await self._process_vector_failures(dlq_file)
            else:
                print(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” íŒŒì¼ í˜•ì‹: {dlq_file.name}")
        
        print(f"\nðŸ“Š ìž¬ì²˜ë¦¬ ì™„ë£Œ: ì„±ê³µ {self.success_count}ê°œ, ì‹¤íŒ¨ {self.failure_count}ê°œ")
    
    async def process_specific_dead_letters(self, failure_type: str, date: str):
        """íŠ¹ì • íƒ€ìž…ê³¼ ë‚ ì§œì˜ Dead Letter ìž¬ì²˜ë¦¬"""
        if failure_type == "crawler":
            filename = f"crawler_failures_{date}.jsonl"
        elif failure_type == "vector":
            filename = f"vector_failures_{date}.jsonl"
        else:
            print(f"âŒ ìž˜ëª»ëœ íƒ€ìž…: {failure_type} (crawler ë˜ëŠ” vector)")
            return
            
        dlq_file = self.dlq_dir / filename
        if not dlq_file.exists():
            print(f"ðŸ“­ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {dlq_file}")
            return
            
        print(f"ðŸ”„ ìž¬ì²˜ë¦¬ ì‹œìž‘: {dlq_file.name}")
        
        if failure_type == "crawler":
            await self._process_crawler_failures(dlq_file)
        else:
            await self._process_vector_failures(dlq_file)
            
        print(f"ðŸ“Š ìž¬ì²˜ë¦¬ ì™„ë£Œ: ì„±ê³µ {self.success_count}ê°œ, ì‹¤íŒ¨ {self.failure_count}ê°œ")
    
    async def _process_crawler_failures(self, dlq_file: Path):
        """í¬ë¡¤ëŸ¬ ì‹¤íŒ¨ ë°ì´í„° ìž¬ì²˜ë¦¬"""
        print("ðŸ•·ï¸ í¬ë¡¤ëŸ¬ ì‹¤íŒ¨ ë°ì´í„° ìž¬ì²˜ë¦¬ ì¤‘...")
        
        crawler = BackroomCrawler()
        await crawler.db.init()
        
        try:
            with open(dlq_file, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    try:
                        record = json.loads(line.strip())
                        
                        if record.get("error_type") == "db_save_failed":
                            # DB ì €ìž¥ ì‹¤íŒ¨ ìž¬ì‹œë„
                            data_dict = record["data"]
                            escape_room = EscapeRoomData(
                                name=data_dict["name"],
                                region=data_dict["region"],
                                sub_region=data_dict["sub_region"],
                                theme=data_dict["theme"],
                                duration=data_dict["duration_minutes"],
                                price=data_dict["price_per_person"],
                                description=data_dict["description"],
                                company=data_dict["company"],
                                rating=data_dict.get("rating"),
                                image_url=data_dict.get("image_url", ""),
                                source_url=data_dict.get("source_url", ""),
                                booking_url=data_dict.get("booking_url", ""),
                                difficulty_level=data_dict.get("difficulty_level", 3),
                                activity_level=data_dict.get("activity_level", 2),
                                group_size_min=data_dict.get("group_size_min", 2),
                                group_size_max=data_dict.get("group_size_max", 4)
                            )
                            
                            success = await crawler._save_to_database(escape_room)
                            if success:
                                print(f"  âœ… ë¼ì¸ {line_num}: {escape_room.name}")
                                self.success_count += 1
                            else:
                                print(f"  âŒ ë¼ì¸ {line_num}: {escape_room.name} (ìž¬ì‹¤íŒ¨)")
                                self.failure_count += 1
                        else:
                            print(f"  âš ï¸ ë¼ì¸ {line_num}: ì¶”ì¶œ ì‹¤íŒ¨ëŠ” ìž¬ì²˜ë¦¬ ë¶ˆê°€")
                            self.failure_count += 1
                            
                    except Exception as e:
                        print(f"  âŒ ë¼ì¸ {line_num} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                        self.failure_count += 1
                        
        finally:
            crawler.teardown_driver()
    
    async def _process_vector_failures(self, dlq_file: Path):
        """ë²¡í„°í™” ì‹¤íŒ¨ ë°ì´í„° ìž¬ì²˜ë¦¬"""
        print("ðŸ”¢ ë²¡í„°í™” ì‹¤íŒ¨ ë°ì´í„° ìž¬ì²˜ë¦¬ ì¤‘...")
        
        generator = VectorGenerator()
        
        # PostgreSQL ì—°ê²°
        import asyncpg

        from app.core.config import settings
        conn = await asyncpg.connect(settings.database_url)
        
        try:
            with open(dlq_file, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    try:
                        record = json.loads(line.strip())
                        
                        if record.get("error_type") == "vectorization_failed":
                            data = record["data"]
                            escape_room_id = data["id"]
                            
                            # DBì—ì„œ ìµœì‹  ë°ì´í„° ë‹¤ì‹œ ì¡°íšŒ
                            row = await conn.fetchrow("""
                                SELECT id, name, description, theme, region, sub_region, company,
                                       difficulty_level, activity_level, duration_minutes, 
                                       price_per_person, group_size_min, group_size_max, rating
                                FROM escape_rooms 
                                WHERE id = $1 AND embedding IS NULL
                            """, escape_room_id)
                            
                            if not row:
                                print(f"  âš ï¸ ë¼ì¸ {line_num}: ID {escape_room_id} - ì´ë¯¸ ë²¡í„°í™”ë¨ ë˜ëŠ” ì‚­ì œë¨")
                                continue
                            
                            # ë²¡í„° ìž¬ìƒì„± ì‹œë„
                            item_dict = dict(row)
                            description = generator._generate_description_from_dict(item_dict)
                            vector = await generator._generate_vector(description)
                            
                            # ë”ë¯¸ ë²¡í„° ì²´í¬
                            if all(v == 0.0 for v in vector):
                                print(f"  âŒ ë¼ì¸ {line_num}: {data['name']} (ì—¬ì „ížˆ ë”ë¯¸ ë²¡í„°)")
                                self.failure_count += 1
                                continue
                            
                            # DB ì—…ë°ì´íŠ¸
                            await conn.execute("""
                                UPDATE escape_rooms 
                                SET embedding = $1 
                                WHERE id = $2
                            """, vector, escape_room_id)
                            
                            print(f"  âœ… ë¼ì¸ {line_num}: {data['name']} (ID: {escape_room_id})")
                            self.success_count += 1
                        else:
                            print(f"  âš ï¸ ë¼ì¸ {line_num}: ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ íƒ€ìž…")
                            self.failure_count += 1
                            
                    except Exception as e:
                        print(f"  âŒ ë¼ì¸ {line_num} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                        self.failure_count += 1
                        
        finally:
            await conn.close()
    
    def archive_processed_files(self):
        """ì²˜ë¦¬ ì™„ë£Œëœ Dead Letter íŒŒì¼ë“¤ì„ ì•„ì¹´ì´ë¸Œ"""
        try:
            archive_dir = self.dlq_dir / "processed"
            archive_dir.mkdir(exist_ok=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            processed_files = []
            for dlq_file in self.dlq_dir.glob("*.jsonl"):
                if dlq_file.parent.name != "processed":  # ì´ë¯¸ ì•„ì¹´ì´ë¸Œëœ íŒŒì¼ ì œì™¸
                    archive_file = archive_dir / f"{dlq_file.stem}_{timestamp}.jsonl"
                    dlq_file.rename(archive_file)
                    processed_files.append(archive_file.name)
            
            if processed_files:
                print(f"ðŸ“¦ {len(processed_files)}ê°œ íŒŒì¼ ì•„ì¹´ì´ë¸Œ ì™„ë£Œ: {archive_dir}")
            
        except Exception as e:
            print(f"âš ï¸ ì•„ì¹´ì´ë¸Œ ì‹¤íŒ¨: {e}")

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    processor = DeadLetterProcessor()
    
    if len(sys.argv) == 1:
        # ëª¨ë“  Dead Letter ìž¬ì²˜ë¦¬
        await processor.process_all_dead_letters()
        
    elif len(sys.argv) == 3:
        # íŠ¹ì • íƒ€ìž…ê³¼ ë‚ ì§œ ìž¬ì²˜ë¦¬
        failure_type = sys.argv[1]
        date = sys.argv[2]
        await processor.process_specific_dead_letters(failure_type, date)
        
    else:
        print("ì‚¬ìš©ë²•:")
        print("  python process_dead_letters.py                    # ëª¨ë“  ì‹¤íŒ¨ ë°ì´í„° ìž¬ì²˜ë¦¬")
        print("  python process_dead_letters.py crawler 20240122   # íŠ¹ì • ë‚ ì§œ í¬ë¡¤ëŸ¬ ì‹¤íŒ¨ ìž¬ì²˜ë¦¬")  
        print("  python process_dead_letters.py vector 20240122    # íŠ¹ì • ë‚ ì§œ ë²¡í„° ì‹¤íŒ¨ ìž¬ì²˜ë¦¬")
        return
    
    # ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ëœ ê²½ìš° ì•„ì¹´ì´ë¸Œ
    if processor.success_count > 0:
        processor.archive_processed_files()

if __name__ == "__main__":
    asyncio.run(main())
