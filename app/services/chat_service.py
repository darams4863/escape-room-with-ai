"""ë°©íƒˆì¶œ ì±—ë´‡ ëŒ€í™” ì „ë‹´ ì„œë¹„ìŠ¤ (í•¨ìˆ˜ ê¸°ë°˜)"""

import re
import uuid
import json
from ..utils.time import now_korea_iso
from typing import List, Dict, Any

from ..core.logger import logger
from ..core.connections import redis_manager
from ..core.constants import PREFERENCE_STEPS
from fastapi import HTTPException

from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from langchain_openai import OpenAIEmbeddings

from ..core.config import settings
from ..core.exceptions import CustomError
from ..models.escape_room import ChatResponse, ChatMessage

from ..repositories.chat_repository import (
    create_session, 
    update_session,
    get_session_by_id,
)
from ..repositories.user_repository import upsert_user_preferences, get_user_preferences
from .nlp_service import (
    analyze_intent,
    analyze_experience_answer,
    analyze_experience_count,
    analyze_difficulty_answer,
    analyze_activity_answer,
    analyze_group_size_answer,
    analyze_region_answer,
    analyze_theme_answer
)

# LLM ê´€ë ¨ë§Œ í´ë˜ìŠ¤ë¡œ ìœ ì§€ (ìƒíƒœ ê´€ë¦¬ í•„ìš”)
class LLMService:
    """LLM ë° ì„ë² ë”© ì„œë¹„ìŠ¤ (ìƒíƒœ ìœ ì§€ í•„ìš”)"""
    
    def __init__(self):
        self.llm = ChatOpenAI(
            model="gpt-3.5-turbo",
            temperature=0.7,
            openai_api_key=settings.openai_api_key
        )
        self.embeddings = OpenAIEmbeddings(openai_api_key=settings.openai_api_key)
        
        # ê²½í—˜ ë“±ê¸‰ë³„ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        self.chat_prompt = PromptTemplate(
            input_variables=["conversation_history", "user_message", "user_level", "user_preferences"],
            template="""
ë‹¹ì‹ ì€ ë°©íƒˆì¶œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ê²½í—˜ ë“±ê¸‰ê³¼ ì„ í˜¸ì‚¬í•­ì„ ê³ ë ¤í•˜ì—¬ ë§ì¶¤í˜• ì¶”ì²œì„ í•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì ì •ë³´:
- ê²½í—˜ ë“±ê¸‰: {user_level}
- ì„ í˜¸ì‚¬í•­: {user_preferences}

ëŒ€í™” ê¸°ë¡:
{conversation_history}

ì‚¬ìš©ì ë©”ì‹œì§€: {user_message}

ë‹¤ìŒ ë‹¨ê³„ë¥¼ ë”°ë¼ ì‘ë‹µí•´ì£¼ì„¸ìš”:

1. ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë¥¼ ì´í•´í•˜ê³  ê³µê°í•´ì£¼ì„¸ìš”
2. ê²½í—˜ ë“±ê¸‰ì— ë§ëŠ” í†¤ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
   - ë°©ìƒì•„/ë°©ë¦°ì´: ì¹œì ˆí•œ ê°€ì´ë“œ í†¤
   - ë°©ì†Œë…„/ë°©ì–´ë¥¸: ë™ë£Œ ê²Œì´ë¨¸ í†¤  
   - ë°©ì‹ /ë°©ì¥ë¡œ: ì¡´ì¤‘ + ë„ì „ ìš•êµ¬ ìê·¹
3. ì„ í˜¸ì‚¬í•­ì„ íŒŒì•…í•˜ê³  ë°˜ì˜í•˜ì„¸ìš” (ë‚œì´ë„, í™œë™ì„±, ì§€ì—­, ì—°ë ¹ëŒ€, ê·¸ë£¹ í¬ê¸° ë“±)
4. ì ì ˆí•œ ë°©íƒˆì¶œì„ ì¶”ì²œí•´ì£¼ì„¸ìš”
5. ê²½í—˜ ë“±ê¸‰ì— ë§ëŠ” ì¡°ì–¸ì„ í¬í•¨í•˜ì„¸ìš”

ì‘ë‹µ í˜•ì‹:
- ë©”ì‹œì§€: ì‚¬ìš©ìì™€ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”
- ì¶”ì²œ ë°©íƒˆì¶œ: 2-3ê°œ ì¶”ì²œ (ìˆë‹¤ë©´)
- ì‚¬ìš©ì í”„ë¡œí•„: íŒŒì•…ëœ ì •ë³´ ìš”ì•½

ì‘ë‹µí•´ì£¼ì„¸ìš”:
"""
        )
        
        # LLMChain ëŒ€ì‹  ìµœì‹  ë°©ì‹ ì‚¬ìš©
        self.chain = self.chat_prompt | self.llm
    
    async def generate_response(self, conversation_history: List[ChatMessage], user_level: str, user_prefs: Dict) -> str:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ ê²½í—˜ ë“±ê¸‰ë³„ ë§ì¶¤ ì‘ë‹µ ìƒì„±"""
        try:
            # ëŒ€í™” ê¸°ë¡ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
            history_text = "\n".join([
                f"{msg.role}: {msg.content}" for msg in conversation_history[-6:]
            ])
            
            # ì‚¬ìš©ì ì„ í˜¸ì‚¬í•­ ìš”ì•½
            prefs_summary = _format_user_preferences(user_prefs)
            
            # ë­ì²´ì¸ ì‹¤í–‰ (ìµœì‹  ë°©ì‹)
            response = await self.chain.ainvoke({
                "conversation_history": history_text,
                "user_message": conversation_history[-1].content,
                "user_level": user_level,
                "user_preferences": prefs_summary
            })
            
            return response.content.strip()
            
        except Exception as e:
            logger.error(f"Response generation error: {e}")
            raise CustomError("OPENAI_ERROR")
    
    async def create_embedding(self, text: str) -> List[float]:
        """í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜"""
        try:
            return await self.embeddings.aembed_query(text)
        except Exception as e:
            logger.error(f"Embedding creation error: {e}")
            raise CustomError("EMBEDDING_ERROR")

# LLM ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
llm_service = LLMService()

# ===== í—¬í¼ í•¨ìˆ˜ë“¤ =====

async def _save_conversation(session_id: str, conversation_history: List[ChatMessage]):
    """ëŒ€í™” ì €ì¥ (Redis + PostgreSQL)"""
    messages_data = []
    for msg in conversation_history:
        timestamp = msg.timestamp.isoformat() if msg.timestamp else now_korea_iso()
        messages_data.append({
            "role": msg.role,
            "content": msg.content,
            "timestamp": timestamp
        })
    
    # Redis + PostgreSQL ì €ì¥
    await redis_manager.set(f"chat_session:{session_id}", json.dumps(messages_data, ensure_ascii=False), ex=86400)
    await update_session(session_id, json.dumps({"messages": messages_data}, ensure_ascii=False))

async def _load_conversation(session_id: str) -> List[ChatMessage]:
    """ëŒ€í™” ë¡œë“œ (Redis â†’ PostgreSQL â†’ Redis ìºì‹œ)"""
    # Redisì—ì„œ ì‹œë„
    conversation_data = await redis_manager.get(f"chat_session:{session_id}")
    if conversation_data:
        return _parse_messages(json.loads(conversation_data))
    
    # PostgreSQLì—ì„œ ë¡œë“œ
    session_data = await get_session_by_id(session_id)
    if session_data:
        conversation_data = session_data['conversation_history']
        # Redisì— ìºì‹œ
        await redis_manager.set(f"chat_session:{session_id}", conversation_data, ex=86400)
        return _parse_messages(json.loads(conversation_data))
    
    return []

def _parse_messages(data: Any) -> List[ChatMessage]:
    """JSON ë°ì´í„°ë¥¼ ChatMessage ë¦¬ìŠ¤íŠ¸ë¡œ íŒŒì‹±"""
    if isinstance(data, list):
        messages_data = data
    elif isinstance(data, dict) and "messages" in data:
        messages_data = data["messages"]
    else:
        return []
    
    messages = []
    for msg_data in messages_data:
        messages.append(ChatMessage(
            role=msg_data["role"],
            content=msg_data["content"],
            timestamp=msg_data.get("timestamp")
        ))
    return messages

# ===== í•¨ìˆ˜ ê¸°ë°˜ ì„œë¹„ìŠ¤ë“¤ =====



async def chat_with_user(
    user_id: int,
    message: str,
    session_id: str | None = None
) -> ChatResponse:
    """í†µí•© ì±„íŒ… ì²˜ë¦¬ - ì„ í˜¸ë„ íŒŒì•… + ë°©íƒˆì¶œ ì¶”ì²œ (Service ê³„ì¸µì—ì„œ ì˜ˆì™¸ ì²˜ë¦¬)"""
    try:
        # ì…ë ¥ ê²€ì¦
        if not message or not message.strip():
            raise CustomError("VALIDATION_ERROR", "ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        if len(message) > 500:
            raise CustomError("VALIDATION_ERROR", "ë©”ì‹œì§€ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤. (ìµœëŒ€ 500ì)")
        
        # XSS ë°©ì§€: ê¸°ë³¸ì ì¸ HTML íƒœê·¸ ì œê±°
        sanitized_message = re.sub(r'<[^>]+>', '', message.strip())
        
        # Rate Limiting ì²´í¬
        is_allowed, status = await redis_manager.rate_limit_check(user_id, limit=20, window=60)
        if not is_allowed:
            raise CustomError("RATE_LIMIT_EXCEEDED", f"ìš”ì²­ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. {status.get('reset_time', 60)}ì´ˆ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        
        # ë¡œê¹…
        logger.user_action(str(user_id), "chat_request", f"Chat request: {sanitized_message[:50]}...")
        
        # ì‚¬ìš©ì ì±— ì„¸ì…˜ í™•ì¸ ë° ìƒì„± 
        session_info = await get_or_create_user_session(user_id, session_id)
        if not session_info:
            raise CustomError("SESSION_CREATION_FAILED", "ì±„íŒ… ì„¸ì…˜ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

        # ìœ ì € ê¸°ë³¸ ì„ í˜¸ë„ ì¡°íšŒ
        user_prefs = await get_user_preferences(user_id)

        # ëŒ€í™” ê¸°ë¡ ë¡œë“œ
        conversation_history = await _load_conversation(session_info["session_id"])
        
        # 1. ì„ í˜¸ë„ íŒŒì•…ì´ í•„ìš”í•œ ê²½ìš°
        if not user_prefs or not _is_preferences_complete(user_prefs):
            response = await handle_preference_flow(
                user_id, session_info["session_id"], conversation_history, user_prefs, sanitized_message
            )
        else:
            # 2. ì„ í˜¸ë„ê°€ ì™„ì„±ëœ ê²½ìš° - ë°©íƒˆì¶œ ì¶”ì²œ ëŒ€í™”
            response = await handle_general_chat(user_id, session_info["session_id"], conversation_history, sanitized_message, user_prefs)
        
        # ì‘ë‹µì— ì„¸ì…˜ ID ì¶”ê°€
        if response:
            response.session_id = session_info["session_id"]
        
        # ë¡œê¹…
        logger.user_action(
            str(user_id), "chat_response", "Chat response generated", 
            session_id=session_info["session_id"],
            chat_type=getattr(response, 'chat_type', 'unknown'),
            is_questionnaire_active=getattr(response, 'is_questionnaire_active', False)
        )
        
        return response
        
    except (CustomError, HTTPException):
        # CustomErrorì™€ HTTPExceptionì€ ê·¸ëŒ€ë¡œ ì „íŒŒ (Global Exception Handlerì—ì„œ ì²˜ë¦¬)
        raise
    except Exception as e:
        # ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬ëŠ” CustomErrorë¡œ ë³€í™˜
        logger.error(f"Unexpected error in chat_with_user: {e}", user_id=user_id, error_type="unexpected_error")
        raise CustomError("CHATBOT_ERROR", "ì±—ë´‡ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

def _is_preferences_complete(user_prefs: Dict) -> bool:
    """ì‚¬ìš©ì ì„ í˜¸ë„ê°€ ì™„ì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸"""
    if not user_prefs:
        return False
    
    required_fields = [
        'experience_level',
        'preferred_difficulty', 
        'preferred_activity_level',
        'preferred_regions',
        'preferred_group_size',
        'preferred_themes'
    ]
    
    for field in required_fields:
        if not user_prefs.get(field):
            return False
    
    return True

async def handle_preference_flow(
    user_id: int, 
    session_id: str, 
    conversation_history: List[ChatMessage], 
    user_prefs: Dict,
    user_message: str
) -> ChatResponse:
    """ë‹¨ê³„ë³„ ì„ í˜¸ë„ íŒŒì•… í”Œë¡œìš°"""
    # í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ë‹¨ê³„ í™•ì¸
    current_step = await _get_current_preference_step(session_id)
    
    # ì‚¬ìš©ìê°€ ì´ì „ ì§ˆë¬¸ì— ë‹µë³€í•œ ê²½ìš°
    if current_step and user_message:
        return await _process_preference_answer(
            user_id, session_id, conversation_history, current_step, user_message, user_prefs
        )
    
    # ìƒˆë¡œìš´ ì„ í˜¸ë„ íŒŒì•… ì‹œì‘ ë˜ëŠ” ë‹¤ìŒ ì§ˆë¬¸
    return await _get_next_preference_question(
        user_id, session_id, current_step, user_prefs
    )

async def _get_current_preference_step(session_id: str) -> str | None:
    """í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ì„ í˜¸ë„ íŒŒì•… ë‹¨ê³„ ì¡°íšŒ (Redis ìš°ì„ , ì‹¤íŒ¨ ì‹œ DB ë³µêµ¬)"""
    try:
        # 1. Redisì—ì„œ ë¨¼ì € í™•ì¸
        current_step = await redis_manager.get(f"preference_step:{session_id}")
        if current_step:
            logger.info(f"Found preference step in Redis: {current_step}")
            return current_step
        
        # 2. Redisì— ì—†ìœ¼ë©´ DBì—ì„œ ë³µêµ¬ ì‹œë„
        logger.info("No preference step in Redis, attempting DB recovery...")
        return await _recover_preference_step_from_db(session_id)
        
    except Exception as e:
        logger.error(f"Error getting preference step: {e}")
        return None

async def _recover_preference_step_from_db(session_id: str) -> str | None:
    """DBì˜ conversation_historyì—ì„œ ì„ í˜¸ë„ ì§„í–‰ ìƒí™© ë³µêµ¬"""
    try:
        # ëŒ€í™” ê¸°ë¡ ë¡œë“œ
        conversation_history = await _load_conversation(session_id)
        if not conversation_history:
            logger.info("No conversation history found, starting fresh")
            return None
        
        # ëŒ€í™” ê¸°ë¡ì—ì„œ ì„ í˜¸ë„ ê´€ë ¨ ì§ˆë¬¸/ë‹µë³€ ë¶„ì„
        completed_steps = _analyze_conversation_for_preference_steps(conversation_history)
        
        if not completed_steps:
            logger.info("No preference steps found in conversation, starting fresh")
            return None
        
        # ë§ˆì§€ë§‰ ì™„ë£Œëœ ë‹¨ê³„ì˜ ë‹¤ìŒ ë‹¨ê³„ ê²°ì •
        last_completed = completed_steps[-1]
        next_step = PREFERENCE_STEPS.get(last_completed, {}).get("next")
        
        if next_step:
            logger.info(f"Recovered preference progress: {last_completed} -> {next_step}")
            # Redisì— ë³µêµ¬ëœ ë‹¨ê³„ ì €ì¥
            await _set_current_preference_step(session_id, next_step)
            return next_step
        else:
            # ëª¨ë“  ë‹¨ê³„ ì™„ë£Œ
            logger.info("All preference steps completed based on conversation history")
            return None
        
    except Exception as e:
        logger.error(f"Failed to recover preference step from DB: {e}")
        return None

def _analyze_conversation_for_preference_steps(conversation_history: List[ChatMessage]) -> List[str]:
    """ëŒ€í™” ê¸°ë¡ì—ì„œ ì™„ë£Œëœ ì„ í˜¸ë„ ë‹¨ê³„ë“¤ ë¶„ì„"""
    completed_steps = []
    
    # ê° ë‹¨ê³„ë³„ ì§ˆë¬¸ê³¼ ë‹µë³€ íŒ¨í„´ ë§¤ì¹­
    step_patterns = {
        "experience_check": {
            "question": "ë°©íƒˆì¶œì€ í•´ë³´ì‹  ì  ìˆë‚˜ìš”?",
            "answers": ["ë„¤, í•´ë´¤ì–´ìš”!", "ì•„ë‹ˆìš”, ì²˜ìŒì´ì—ìš”."]
        },
        "experience_count": {
            "question": "ëª‡ ë²ˆ ì •ë„ í•´ë³´ì…¨ë‚˜ìš”?",
            "answers": ["1-10íšŒ", "11-30íšŒ", "31-50íšŒ", "51-80íšŒ", "81-100íšŒ", "100íšŒ ì´ìƒ"]
        },
        "difficulty_check": {
            "question": "ì–´ë–¤ ë‚œì´ë„ë¥¼ ì„ í˜¸í•˜ì‹œë‚˜ìš”?",
            "answers": ["ğŸ”’", "ğŸ”’ğŸ”’", "ğŸ”’ğŸ”’ğŸ”’"]
        },
        "activity_level_check": {
            "question": "í™œë™ì„± ìˆ˜ì¤€ì€ ì–´ë–»ê²Œ í•˜ì‹œë‚˜ìš”?",
            "answers": ["ê±°ì˜ ì—†ìŒ", "ë³´í†µ", "ë§ìŒ"]
        },
        "group_size_check": {
            "question": "ëª‡ ëª…ì´ì„œ ê°€ì‹œë‚˜ìš”?",
            "answers": ["2ëª…", "3ëª…", "4ëª…", "5ëª… ì´ìƒ"]
        },
        "region_check": {
            "question": "ì–´ëŠ ì§€ì—­ì„ ì„ í˜¸í•˜ì‹œë‚˜ìš”?",
            "answers": ["ê°•ë‚¨", "í™ëŒ€", "ê±´ëŒ€", "ì‹ ì´Œ", "ê¸°íƒ€"]
        },
        "themes_check": {
            "question": "ì–´ë–¤ í…Œë§ˆë¥¼ ì„ í˜¸í•˜ì‹œë‚˜ìš”?",
            "answers": ["ì¶”ë¦¬", "ê³µí¬", "íŒíƒ€ì§€", "SF", "ìŠ¤ë¦´ëŸ¬", "ëª¨í—˜"]
        }
    }
    
    # ëŒ€í™” ê¸°ë¡ì„ ìˆœíšŒí•˜ë©° ì§ˆë¬¸-ë‹µë³€ ìŒ ì°¾ê¸°
    for i in range(len(conversation_history) - 1):
        assistant_msg = conversation_history[i]
        user_msg = conversation_history[i + 1]
        
        if assistant_msg.role == "assistant" and user_msg.role == "user":
            assistant_content = assistant_msg.content
            user_content = user_msg.content
            
            # ê° ë‹¨ê³„ë³„ë¡œ ì§ˆë¬¸ê³¼ ë‹µë³€ ë§¤ì¹­ í™•ì¸
            for step, pattern in step_patterns.items():
                if step in completed_steps:
                    continue
                    
                # ì§ˆë¬¸ íŒ¨í„´ ë§¤ì¹­
                question_match = any(
                    pattern["question"] in assistant_content or 
                    q in assistant_content for q in [pattern["question"]]
                )
                
                # ë‹µë³€ íŒ¨í„´ ë§¤ì¹­
                answer_match = any(
                    answer in user_content for answer in pattern["answers"]
                )
                
                if question_match and answer_match:
                    completed_steps.append(step)
                    logger.info(f"Found completed step: {step} (Q: {assistant_content[:50]}... A: {user_content})")
                    break
    
    return completed_steps
        
async def _get_next_preference_question(
    user_id: int, 
    session_id: str, 
    current_step: str | None, 
    user_prefs: Dict
) -> ChatResponse:
    """ë‹¤ìŒ ì„ í˜¸ë„ ì§ˆë¬¸ ë°˜í™˜ (ë³µêµ¬ ë¡œì§ í¬í•¨)"""
    
    # Redisì—ì„œ ì§„í–‰ ë‹¨ê³„ê°€ ì—†ìœ¼ë©´ DBì—ì„œ ë³µêµ¬ ì‹œë„
    if not current_step:
        current_step = await _recover_preference_step_from_db(session_id)
    
    # ì²« ë²ˆì§¸ ì§ˆë¬¸ì¸ ê²½ìš°
    if not current_step:
        return await _handle_first_preference_question(session_id)
        
    # ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰
    next_step = PREFERENCE_STEPS.get(current_step, {}).get("next")
    if next_step:
        return await _handle_next_preference_question(session_id, current_step, next_step)
        
    # ëª¨ë“  ì§ˆë¬¸ ì™„ë£Œ
    return await _complete_preferences(user_id, session_id, user_prefs)

async def _handle_first_preference_question(session_id: str) -> ChatResponse:
    """ì²« ë²ˆì§¸ ì„ í˜¸ë„ ì§ˆë¬¸ ì²˜ë¦¬"""
    next_step = "experience_check"
    await _set_current_preference_step(session_id, next_step)
    
    # AI ì§ˆë¬¸ì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
    ai_message = ChatMessage(
        role="assistant",
        content=_get_greeting_message()
    )
    conversation_history = [ai_message]
    await _save_conversation(session_id, conversation_history)
    
    return ChatResponse(
        message=_get_greeting_message(),
        session_id=session_id,
        questionnaire={
            "type": next_step,
            "question": PREFERENCE_STEPS[next_step]["question"],
            "options": PREFERENCE_STEPS[next_step]["options"],
            "next_step": PREFERENCE_STEPS[next_step]["next"]
        },
        chat_type="preference_start",
        is_questionnaire_active=True
    )

async def _handle_next_preference_question(session_id: str, current_step: str, next_step: str) -> ChatResponse:
    """ë‹¤ìŒ ì„ í˜¸ë„ ì§ˆë¬¸ ì²˜ë¦¬"""
    await _set_current_preference_step(session_id, next_step)
    
    # ë³µêµ¬ëœ ê²½ìš°ì™€ ìƒˆë¡œ ì§„í–‰í•˜ëŠ” ê²½ìš° ë©”ì‹œì§€ êµ¬ë¶„
    message = _get_next_question_message(current_step)
    
    # AI ì§ˆë¬¸ì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
    ai_message = ChatMessage(
        role="assistant",
        content=message
    )
    conversation_history = [ai_message]
    await _save_conversation(session_id, conversation_history)
    
    return ChatResponse(
        message=message,
        session_id=session_id,
        questionnaire={
            "type": next_step,
            "question": PREFERENCE_STEPS[next_step]["question"],
            "options": PREFERENCE_STEPS[next_step]["options"],
            "next_step": PREFERENCE_STEPS[next_step].get("next")
        },
        chat_type="preference_question",
        is_questionnaire_active=True
    )

def _get_next_question_message(current_step: str) -> str:
    """ë‹¤ìŒ ì§ˆë¬¸ ë©”ì‹œì§€ ìƒì„±"""
    if current_step in ["experience_check", "experience_count", "difficulty_check", 
                       "activity_level_check", "group_size_check", "region_check"]:
        return "ì¢‹ìŠµë‹ˆë‹¤! ë‹¤ìŒ ì§ˆë¬¸ì…ë‹ˆë‹¤."
    else:
        return "ì´ì–´ì„œ ë‹¤ìŒ ì§ˆë¬¸ì„ ë“œë¦´ê²Œìš”."

async def _process_preference_answer(
    user_id: int, 
    session_id: str, 
    conversation_history: List[ChatMessage],
    current_step: str, 
    user_answer: str, 
    user_prefs: Dict
) -> ChatResponse:
    """ì‚¬ìš©ì ë‹µë³€ ì²˜ë¦¬ ë° ë‹¤ìŒ ë‹¨ê³„ ê²°ì • (ì˜ˆì™¸ ì²˜ë¦¬ ê°•í™”)"""
    try:
        user_message = ChatMessage(
            role="user",
            content=user_answer
        )
        conversation_history.append(user_message)
        
        # ë‹µë³€ì„ ì„ í˜¸ë„ì— ì €ì¥ (ì˜ˆì™¸ ì²˜ë¦¬ í¬í•¨)
        await _save_preference_answer(user_id, current_step, user_answer, user_prefs)
        
        # ëŒ€í™” ê¸°ë¡ ì €ì¥
        await _save_conversation(session_id, conversation_history)
        
        # ë‹¤ìŒ ë‹¨ê³„ ê²°ì •
        next_step = PREFERENCE_STEPS.get(current_step, {}).get("next")
        
        if next_step:
            # ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ì§„í–‰
            await _set_current_preference_step(session_id, next_step)
            return await _get_next_preference_question(user_id, session_id, next_step, user_prefs)
        else:
            # ëª¨ë“  ì§ˆë¬¸ ì™„ë£Œ
            return await _complete_preferences(user_id, session_id, user_prefs)
            
    except CustomError as e:
        # ì„ í˜¸ë„ ì €ì¥ ì‹¤íŒ¨ ì‹œ ì‚¬ìš©ìì—ê²Œ ì¬ì‹œë„ ìš”ì²­
        logger.error(f"Preference processing failed: {e.message}")
        return ChatResponse(
        message=f"ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\n\n{user_answer}",
            session_id=session_id,
            questionnaire={
            "type": current_step,
            "question": PREFERENCE_STEPS[current_step]["question"],
            "options": PREFERENCE_STEPS[current_step]["options"],
            "next_step": PREFERENCE_STEPS[current_step].get("next")
        },
        chat_type="preference_retry",
            is_questionnaire_active=True
        )
    except Exception as e:
        # ê¸°íƒ€ ì˜ˆì™¸ ë°œìƒ ì‹œ
        logger.error(f"Unexpected error in preference processing: {e}")
        return ChatResponse(
            message="ì£„ì†¡í•©ë‹ˆë‹¤. ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
            session_id=session_id,
            questionnaire=None,
            chat_type="error",
            is_questionnaire_active=False
        )

async def _complete_preferences(user_id: int, session_id: str, user_prefs: Dict) -> ChatResponse:
    """ì„ í˜¸ë„ íŒŒì•… ì™„ë£Œ ë° ì¼ë°˜ ëŒ€í™” ì‹œì‘ (ì˜ˆì™¸ ì²˜ë¦¬ í¬í•¨)"""
    try:
        # Redisì—ì„œ ì§„í–‰ ë‹¨ê³„ ì œê±°
        await redis_manager.delete(f"preference_step:{session_id}")
        logger.info(f"Preference flow completed for user {user_id}, session {session_id}")
        
        # ì™„ë£Œ ë©”ì‹œì§€
        completion_message = (
            "ğŸ‰ **ëª¨ë“  ì„ í˜¸ë„ íŒŒì•…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!**\n\n"
            "ì´ì œ ë‹¹ì‹ ì—ê²Œ ë”± ë§ëŠ” ë°©íƒˆì¶œì„ ì¶”ì²œí•´ë“œë¦´ê²Œìš”!\n"
            "ì–´ë–¤ ë°©íƒˆì¶œì„ ì°¾ê³  ê³„ì‹ ê°€ìš”?\n\n"
            "**ì˜ˆì‹œ:**\n"
            "- 'ê°•ë‚¨ì—ì„œ 3ì¸ ë°©íƒˆì¶œ ì¶”ì²œí•´ì¤˜'\n"
            "- 'ì¶”ë¦¬ í…Œë§ˆë¡œ í™œë™ì„± ë†’ì€ ë°©íƒˆì¶œ ì¶”ì²œí•´ì¤˜'\n"
            "- 'ë‚œì´ë„ ë†’ì€ ë°©íƒˆì¶œ ì¶”ì²œí•´ì¤˜'"
        )
        
        # ì™„ë£Œ ë©”ì‹œì§€ë¥¼ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
        ai_message = ChatMessage(
            role="assistant",
            content=completion_message
        )
        await _save_conversation(session_id, [ai_message])
        
        return ChatResponse(
            message=completion_message,
            session_id=session_id,
            questionnaire=None,
            chat_type="preference_complete",
            is_questionnaire_active=False
        )
        
    except Exception as e:
        logger.error(f"Error completing preferences: {e}")
        # ì™„ë£Œ ì²˜ë¦¬ ì‹¤íŒ¨í•´ë„ ì‚¬ìš©ìì—ê²ŒëŠ” ì„±ê³µ ë©”ì‹œì§€ í‘œì‹œ
        return ChatResponse(
            message="ì„ í˜¸ë„ íŒŒì•…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì´ì œ ë°©íƒˆì¶œì„ ì¶”ì²œí•´ë“œë¦´ê²Œìš”.",
            session_id=session_id,
            questionnaire=None,
            chat_type="preference_complete",
            is_questionnaire_active=False
        )
        
async def _set_current_preference_step(session_id: str, step: str):
    """í˜„ì¬ ì„ í˜¸ë„ íŒŒì•… ë‹¨ê³„ë¥¼ Redisì— ì €ì¥"""
    try:
        await redis_manager.set(
            key=f"preference_step:{session_id}",
            value=step,
            ex=86400  # 24ì‹œê°„ TTL (ë” ê¸´ ì‹œê°„)
        )
        logger.info(f"Preference step saved: {step}")
    except Exception as e:
        logger.error(f"Failed to save preference step: {e}")
        # Redis ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰ (DBì—ì„œ ë³µêµ¬ ê°€ëŠ¥)

def _get_greeting_message() -> str:
    """ì‚¬ìš©ì ì¸ì‚¬ ë©”ì‹œì§€ ìƒì„±"""
    return (
        f"ì•ˆë…•í•˜ì„¸ìš”! ğŸ‰ **AI ë°©íƒˆì¶œ ì›”ë“œ**ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!\n\n"
        "ì €ëŠ” ë‹¹ì‹ ì—ê²Œ ë”± ë§ëŠ” ë°©íƒˆì¶œì„ ì¶”ì²œí•´ë“œë¦¬ëŠ” AIì…ë‹ˆë‹¤!\n\n"
        "**ë°©íƒˆì¶œì€ í•´ë³´ì‹  ì  ìˆë‚˜ìš”?**\n"
        "ê²½í—˜ì— ë”°ë¼ ë§ì¶¤í˜• ì¶”ì²œì„ í•´ë“œë¦´ê²Œìš”! ğŸ˜Š"
    )
                
async def _save_preference_answer(user_id: int, step: str, answer: str, user_prefs: Dict):
    """ì‚¬ìš©ì ë‹µë³€ì„ ì„ í˜¸ë„ì— ì €ì¥ (LLM ê¸°ë°˜ ìì—°ì–´ ì²˜ë¦¬)"""
    try:
        step_info = PREFERENCE_STEPS.get(step, {})
        field = step_info.get("field")
        
        if not field:
            logger.warning(f"Unknown step: {step}")
            return
        
        # LLM ê¸°ë°˜ ë‹µë³€ ë¶„ì„ ë° ì €ì¥
        if step == "experience_check":
            analyzed_answer = await analyze_experience_answer(answer)
            if analyzed_answer == "experienced":
                user_prefs[field] = "ë°©ì†Œë…„"  # ê¸°ë³¸ê°’
            else:
                user_prefs[field] = "ë°©ìƒì•„"
                
        elif step == "experience_count":
            analyzed_count = await analyze_experience_count(answer)
            user_prefs[field] = analyzed_count["count"]
            user_prefs['experience_level'] = analyzed_count["level"]
            
        elif step == "difficulty_check":
            difficulty = await analyze_difficulty_answer(answer)
            user_prefs[field] = difficulty
            
        elif step == "activity_level_check":
            activity_level = await analyze_activity_answer(answer)
            user_prefs[field] = activity_level
            
        elif step == "group_size_check":
            group_size = await analyze_group_size_answer(answer)
            user_prefs[field] = group_size
            
        elif step == "region_check":
            region = await analyze_region_answer(answer)
            user_prefs[field] = [region]
            
        elif step == "themes_check":
            theme = await analyze_theme_answer(answer)
            user_prefs[field] = [theme]
        
        # ì„ í˜¸ë„ ì—…ë°ì´íŠ¸
        await upsert_user_preferences(user_id, user_prefs)
        logger.info(f"Preference saved successfully: {step} = {user_prefs.get(field)}")
            
    except Exception as e:
        logger.error(f"Failed to save preference answer: {e}", step=step, answer=answer)
        # DB ì €ì¥ ì‹¤íŒ¨ ì‹œì—ë„ ì§„í–‰ ë‹¨ê³„ëŠ” ìœ ì§€ (ì¬ì‹œë„ ê°€ëŠ¥)
        raise CustomError("PREFERENCE_SAVE_FAILED", f"ì„ í˜¸ë„ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}")

async def get_or_create_user_session(user_id: int, session_id: str | None = None) -> Dict[str, Any] | None:
    """ì‚¬ìš©ìë³„ ì„¸ì…˜ í™•ì¸ ë° ìƒì„± (í•˜ë‚˜ë§Œ í—ˆìš©)"""
    # 1. ê¸°ì¡´ ì„¸ì…˜ì´ ìˆëŠ”ì§€ í™•ì¸
    existing_session_key = f"user_session:{user_id}"
    existing_session = await redis_manager.get(existing_session_key)
    
    if existing_session:
        # ê¸°ì¡´ ì„¸ì…˜ì´ ìˆìœ¼ë©´ ê·¸ê±¸ ì‚¬ìš©
        existing_data = json.loads(existing_session)
        return {"session_id": existing_data["session_id"], "is_new": False}
    
    # 2. ìƒˆ ì„¸ì…˜ ìƒì„±
    new_session_id = str(uuid.uuid4())
    
    # Repository í•¨ìˆ˜ ì‚¬ìš©
    success = await create_session(str(user_id), new_session_id)
    if not success:
        return None
        
    # Redisì— ì„¸ì…˜ ì •ë³´ ì €ì¥ (í•˜ë‚˜ë§Œ)
    session_data = {
        "session_id": new_session_id,
        "user_id": user_id,
        "created_at": now_korea_iso()
    }
    
    await redis_manager.set(
        
        key=existing_session_key,
        value=json.dumps(session_data, ensure_ascii=False),
        ex=86400  # 24ì‹œê°„ TTL
    )
        
    return {"session_id": new_session_id, "is_new": True}
        
async def handle_general_chat(
    user_id: int, 
    session_id: str, 
    conversation_history: List[ChatMessage],
    user_message: str, 
    user_prefs: Dict, 
) -> ChatResponse:
    """ë°©íƒˆì¶œ ì¶”ì²œì„ ìœ„í•œ ì¼ë°˜ ì±—ë´‡ ëŒ€í™” ì²˜ë¦¬"""
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    user_message_obj = ChatMessage(
            role="user",
        content=user_message
    )
    conversation_history.append(user_message_obj)
    
    # ì‚¬ìš©ì ì˜ë„ íŒŒì•… (ì‹¤ì œ LLM ê¸°ë°˜)
    user_intent = await _analyze_user_intent_with_llm(user_message, conversation_history)
    
    # ì˜ë„ë³„ ì²˜ë¦¬ ë¡œì§
    if user_intent["intent"] == "recommendation":
        return await _handle_recommendation_request(
            session_id, user_id, user_message, user_prefs, conversation_history, user_intent
        )
    elif user_intent["intent"] in ["question", "general_chat"]:
        # question, general_chat, ê¸°íƒ€ ëª¨ë“  ê²½ìš°ë¥¼ í•˜ë‚˜ë¡œ í†µí•©
        return await _handle_general_response(
            session_id, user_id, user_message, user_prefs, conversation_history, user_intent
        )
    else:
        # ì˜ë„ íŒŒì•… ì‹¤íŒ¨ ì‹œ ëª…í™•í•œ ì§ˆë¬¸
        return await _handle_unclear_intent(session_id, user_message)


async def _analyze_user_intent_with_llm(user_message: str, conversation_history: List[ChatMessage]) -> Dict:
    """LLMì„ ì‚¬ìš©í•œ ì‹¤ì œ ì˜ë„ ë¶„ì„"""
    intent_result = await analyze_intent(user_message)
    
    # ê²°ê³¼ì— ëŒ€í™” ë§¥ë½ ì •ë³´ ì¶”ê°€
    intent_result["conversation_context"] = [
        {
            "role": msg.role,
            "content": msg.content,
            "timestamp": msg.timestamp.isoformat() if msg.timestamp else None
        }
        for msg in conversation_history[-6:]  # ìµœê·¼ 6ê°œ ë©”ì‹œì§€ë§Œ (í† í° ì ˆì•½)
    ]
    
    return intent_result


async def _handle_recommendation_request(
    session_id: str, 
    user_id: int, 
    user_message: str, 
    user_prefs: Dict, 
    conversation_history: List[ChatMessage],
    user_intent: Dict
) -> ChatResponse:
    """ë°©íƒˆì¶œ ì¶”ì²œ ìš”ì²­ ì²˜ë¦¬"""
    # ì—”í‹°í‹°ì—ì„œ ì¶”ì²œ ì¡°ê±´ ì¶”ì¶œ
    entities = user_intent.get("entities", {})
    
    # ì‹¤ì œ ë°©íƒˆì¶œ ì¶”ì²œ ì¡°íšŒ
    from ..services.recommendation_service import get_escape_room_recommendations
    recommendations = await get_escape_room_recommendations(user_message, user_prefs)
    
    # ì¶”ì²œ ê²°ê³¼ë¥¼ í¬í•¨í•œ ì‘ë‹µ ìƒì„±
    if recommendations:
        # ì¶”ì²œ ê²°ê³¼ ìš”ì•½
        rec_summary = "\n".join([
            f"â€¢ {rec.name} ({rec.theme}, {rec.region}, ë‚œì´ë„: {rec.difficulty_level})"
            for rec in recommendations[:3]
        ])
        
        response_text = f"""
{entities.get('region', '')}ì—ì„œ {entities.get('theme', '')} í…Œë§ˆë¡œ ì¶”ì²œí•´ë“œë¦´ê²Œìš”!

ğŸ¯ **ì¶”ì²œ ë°©íƒˆì¶œ:**
{rec_summary}

ë” ìì„¸í•œ ì •ë³´ë‚˜ ë‹¤ë¥¸ ì¡°ê±´ìœ¼ë¡œ ì¶”ì²œë°›ê³  ì‹¶ìœ¼ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”!
"""
    else:
        response_text = "ì£„ì†¡í•©ë‹ˆë‹¤. ì¡°ê±´ì— ë§ëŠ” ë°©íƒˆì¶œì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì¡°ê±´ìœ¼ë¡œ ì‹œë„í•´ë³´ì‹œê² ì–´ìš”?"
    
    # ì‘ë‹µ ì €ì¥ ë° ë°˜í™˜
    ai_message = ChatMessage(role="assistant", content=response_text)
    conversation_history.append(ai_message)
    await _save_conversation(session_id, conversation_history)
    
    return ChatResponse(
        message=response_text,
        session_id=session_id,
        questionnaire=None,
        recommendations=recommendations[:3] if recommendations else None,
        user_profile=await extract_user_profile(conversation_history, user_prefs),
        chat_type="recommendation",
        is_questionnaire_active=False
    )
        

async def _handle_general_response(
    session_id: str, 
    user_id: int, 
    user_message: str, 
    user_prefs: Dict, 
    conversation_history: List[ChatMessage],
    user_intent: Dict
) -> ChatResponse:
    """í†µí•©ëœ ì¼ë°˜ ì‘ë‹µ ì²˜ë¦¬ (ì§ˆë¬¸, ì¼ë°˜ ëŒ€í™”, ì˜ë„ ë¶ˆëª… ë“±)"""
    # ì˜ë„ì— ë”°ë¥¸ ì ì ˆí•œ ì‘ë‹µ ìƒì„±
    intent = user_intent.get("intent", "general_chat")
    
    if intent == "question":
        # ì§ˆë¬¸ì¸ ê²½ìš° ë” êµ¬ì²´ì ì¸ ë‹µë³€
        response_text = await llm_service.generate_response(
            conversation_history, 
            user_prefs.get('experience_level', 'ë°©ìƒì•„'), 
            user_prefs
        )
        chat_type = "question"
    else:
        # ì¼ë°˜ ëŒ€í™” ë˜ëŠ” ì˜ë„ ë¶ˆëª…ì¸ ê²½ìš° ì¹œê·¼í•œ ì‘ë‹µ
        response_text = await llm_service.generate_response(
            conversation_history, 
            user_prefs.get('experience_level', 'ë°©ìƒì•„'), 
            user_prefs
        )
        chat_type = "general"
        
        # AI ì‘ë‹µ ì¶”ê°€
        ai_message = ChatMessage(role="assistant", content=response_text)
        conversation_history.append(ai_message)
        await _save_conversation(session_id, conversation_history)
        
        return ChatResponse(
            message=response_text,
            session_id=session_id,
            questionnaire=None,
            recommendations=None,
            user_profile=await extract_user_profile(conversation_history, user_prefs),
            chat_type=chat_type,
            is_questionnaire_active=False
        )
        
async def _handle_unclear_intent(session_id: str, user_message: str) -> ChatResponse:
    """ì˜ë„ íŒŒì•… ì‹¤íŒ¨ ì‹œ ì²˜ë¦¬"""
    clarification_message = f"""
ì£„ì†¡í•©ë‹ˆë‹¤. "{user_message}"ì˜ ì˜ë„ë¥¼ ì •í™•íˆ íŒŒì•…í•˜ì§€ ëª»í–ˆì–´ìš”.

ë‹¤ìŒ ì¤‘ ì–´ë–¤ ê²ƒì„ ì›í•˜ì‹œë‚˜ìš”?

1. ğŸ¯ **ë°©íƒˆì¶œ ì¶”ì²œ**: "ê°•ë‚¨ì—ì„œ ì¶”ë¦¬ í…Œë§ˆë¡œ ì¶”ì²œí•´ì¤˜"
2. â“ **ì§ˆë¬¸**: "ë°©íƒˆì¶œì´ ë­ì˜ˆìš”?"
3. ğŸ’¬ **ì¼ë°˜ ëŒ€í™”**: "ì•ˆë…•í•˜ì„¸ìš”"

êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ì£¼ì‹œë©´ ë” ì •í™•í•œ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆì–´ìš”!
"""
    
    return ChatResponse(
        message=clarification_message,
        session_id=session_id,
        questionnaire={
            "type": "intent_clarification",
            "question": "ì–´ë–¤ ê²ƒì„ ì›í•˜ì‹œë‚˜ìš”?",
            "options": ["ë°©íƒˆì¶œ ì¶”ì²œ", "ì§ˆë¬¸", "ì¼ë°˜ ëŒ€í™”"],
            "next_step": "intent_confirmed"
        },
        chat_type="clarification",
        is_questionnaire_active=True
    )


def _format_user_preferences(user_prefs: Dict) -> str:
    """ì‚¬ìš©ì ì„ í˜¸ì‚¬í•­ì„ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…"""
    if not user_prefs:
        return "ì •ë³´ ì—†ìŒ"
    
    parts = []
    if user_prefs.get('experience_level'):
        parts.append(f"ê²½í—˜ ë“±ê¸‰: {user_prefs['experience_level']}")
    if user_prefs.get('experience_count'):
        parts.append(f"ê²½í—˜ íšŸìˆ˜: {user_prefs['experience_count']}íšŒ")
    if user_prefs.get('preferred_difficulty'):
        parts.append(f"ì„ í˜¸ ë‚œì´ë„: {user_prefs['preferred_difficulty']}")
    if user_prefs.get('preferred_regions'):
        parts.append(f"ì„ í˜¸ ì§€ì—­: {', '.join(user_prefs['preferred_regions'])}")
    
    return ", ".join(parts) if parts else "ì •ë³´ ì—†ìŒ"

async def extract_user_profile(conversation_history: List[ChatMessage], user_prefs: Dict) -> Dict[str, Any] | None:
    """ëŒ€í™” ê¸°ë¡ê³¼ ì„ í˜¸ì‚¬í•­ì—ì„œ ì‚¬ìš©ì í”„ë¡œí•„ ì¶”ì¶œ"""
    # ìµœê·¼ ëŒ€í™”ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
    recent_messages = " ".join([
        msg.content for msg in conversation_history[-4:] if msg.role == "user"
    ])
    
    profile = {
        "experience_level": user_prefs.get('experience_level', 'ë°©ìƒì•„') if user_prefs else 'ë°©ìƒì•„',
        "experience_count": user_prefs.get('experience_count'),
        "preferred_difficulty": user_prefs.get('preferred_difficulty'),
        "preferred_regions": user_prefs.get('preferred_regions', []),
        "preferred_group_size": None
    }
    
    # ê·¸ë£¹ ì‚¬ì´ì¦ˆ ì¶”ì¶œ
    group_size = parse_group_size(recent_messages)
    if group_size:
        profile["preferred_group_size"] = group_size
    
    return profile
        


def parse_group_size(message: str) -> int | str | None:
    """ìœ ì—°í•œ ì¸ì›ìˆ˜ íŒŒì‹±"""
    # ìˆ«ì + "ëª…" íŒ¨í„´
    numbers_with_unit = re.findall(r'(\d+)ëª…', message)
    if numbers_with_unit:
        return int(numbers_with_unit[0])
    
    # ë‹¨ìˆœ ìˆ«ì íŒ¨í„´
    if any(word in message for word in ["ì¸ì›", "ì‚¬ëŒ", "ëª…", "ê·¸ë£¹"]):
        numbers = re.findall(r'\b(\d+)\b', message)
        for num in numbers:
            num_int = int(num)
            if 1 <= num_int <= 10:
                return num_int
    
    # í•œê¸€ ìˆ«ì
    korean_numbers = {
        "í•œ": 1, "í•˜ë‚˜": 1, "í˜¼ì": 1,
        "ë‘˜": 2, "ë‘": 2, "ì»¤í”Œ": 2, "ì—°ì¸": 2,
        "ì…‹": 3, "ì„¸": 3, "ì‚¼": 3,
        "ë„·": 4, "ë„¤": 4, "ì‚¬": 4,
        "ë‹¤ì„¯": 5, "ì˜¤": 5,
        "ì—¬ì„¯": 6, "ìœ¡": 6
    }
    
    for korean, number in korean_numbers.items():
        if korean in message:
            return number
    
    return None

