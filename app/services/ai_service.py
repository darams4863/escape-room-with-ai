"""AI ì„œë¹„ìŠ¤ (NLP + RAG) - ì˜ë„ ë¶„ì„, ì—”í‹°í‹° ì¶”ì¶œ, ê²€ìƒ‰"""

import json
import time
from typing import Any, Dict, List

from langchain.schema import HumanMessage

from ..core.exceptions import CustomError
from ..core.llm import llm
from ..core.logger import logger
from ..core.monitor import track_api_call, track_performance
from ..repositories.escape_room_repository import get_intent_patterns_from_db
from ..utils.time import now_korea_iso

# =============================================================================
# ì˜ë„ ë¶„ì„ ë° ì—”í‹°í‹° ì¶”ì¶œ
# =============================================================================

@track_performance("intent_analysis")
async def analyze_intent(user_message: str) -> Dict[str, Any]:
    """í•˜ì´ë¸Œë¦¬ë“œ ì˜ë„ ë¶„ì„: LLM ìš°ì„ , DB fallback"""
    try:
        # 1. LLM ê¸°ë°˜ ì˜ë„ ë¶„ì„ ì‹œë„
        llm_result = await _analyze_intent_with_llm(user_message)
        
        # 2. LLM ê²°ê³¼ê°€ ì‹ ë¢°í•  ë§Œí•˜ë©´ ì‚¬ìš©
        if llm_result.get("confidence", 0) > 0.6:
            logger.info(f"LLM intent analysis successful: {llm_result}")
            return llm_result
        
        # TODO: # ğŸ”¥ ì—¬ê¸°ì— í’ˆì§ˆ í‰ê°€ ì¶”ê°€ (ê¸°ì¡´ ì‹ ë¢°ë„ íŒë‹¨ ë°©ì‹ í™œìš©) e.g. evaluate_response_quality ì´ëŸ°ê±° ë§Œë“¤ì–´ì„œ ì‹¤ì œë¡œ llmì´ ë°˜í™˜í•œ resposneê°€ ìœ ì €ì˜ ìš”ì²­ê³¼ ë¶€í•©í•˜ëŠ”ì§€ í’ˆì§ˆì„ í‰ê°€í•˜ëŠ” ë¡œì§ -> ë§¤íŠ¸ë¦­ ìˆ˜ì§‘ -> grafanaë¡œ ì‹¤íŒ¨ ë§¤íŠ¸ë¦­ ë³´ì—¬ì£¼ê¸° && ì¬ì‹œë„ ë¡œì§ì´ ë¹”.
        # TODO:  ì‹¤ì œ BLEU, ROUGE, BERTScore ë¼ì´ë¸ŒëŸ¬ë¦¬ ë„ì… ë° ê³„ì‚° ë„ì…ì„ ê³ ë ¤í•´ ë³¼ê²ƒ .
        # ê·¸ë¦¬ê³  ë‚˜ì„œ ìœ„ì—ì„œ ìŠ¤ì½”ì–´ ê¸°ë°˜ìœ¼ë¡œ íŠ¹ì • ì ìˆ˜ ì´í•˜ì¼ ë•Œ ìë™ ì¬ìƒì„± í•˜ëŠ” ì‹œìŠ¤í…œ ë„ì…í•  ê²ƒ 

        # 3. LLM ì‹¤íŒ¨ ì‹œ DB íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ fallback
        logger.info("LLM analysis failed, falling back to pattern matching")
        return await _analyze_intent_pattern_fallback(user_message)
        
    except Exception as e:
        logger.error(f"Hybrid intent analysis error: {e}")
        return await _analyze_intent_pattern_fallback(user_message)

async def _analyze_intent_with_llm(user_message: str) -> Dict[str, Any]:
    """LLMì„ ì‚¬ìš©í•œ ì‘ë‹µ ìœ í˜• ë¶„ì„"""
    try:
        prompt = f"""
ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ë¶„ì„í•˜ì—¬ ì–´ë–¤ ì¢…ë¥˜ì˜ ì‘ë‹µì„ ì›í•˜ëŠ”ì§€ íŒŒì•…í•˜ê³ , ë°©íƒˆì¶œ ê´€ë ¨ ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì ë©”ì‹œì§€: {user_message}

ë‹¤ìŒ ì¤‘ í•˜ë‚˜ì˜ ì‘ë‹µ ìœ í˜•ì„ ì„ íƒí•˜ê³  JSON í˜•íƒœë¡œ ì‘ë‹µí•˜ì„¸ìš”:

1. "room_recommendation" - êµ¬ì²´ì ì¸ ë°©íƒˆì¶œ ì¶”ì²œ ìš”ì²­
   - ì˜ˆ: "ê°•ë‚¨ì—ì„œ ì¶”ë¦¬ í…Œë§ˆë¡œ ì¶”ì²œí•´ì¤˜", "4ëª…ì´ í•  ìˆ˜ ìˆëŠ” ë°©íƒˆì¶œ ì°¾ì•„ì¤˜", "ë‚¨ìì¹œêµ¬ë‘ ê°•ë‚¨ì—ì„œ ë°©íƒˆì¶œí• ê±´ë° ì¶”ì²œí•´ì¤˜"
   
2. "room_inquiry" - ë°©íƒˆì¶œì— ëŒ€í•œ ì •ë³´ ì§ˆë¬¸
   - ì˜ˆ: "ë°©íƒˆì¶œì´ ë­ì•¼?", "ë‚œì´ë„ 3ì€ ì–´ëŠ ì •ë„ì•¼?", "ë°©íƒˆì¶œ ê°€ê²©ì€ ë³´í†µ ì–¼ë§ˆì•¼?", "ë°©íƒˆì¶œ ì–´ë–»ê²Œ í•˜ëŠ”ê±°ì•¼?"
   
3. "general_chat" - ì¼ë°˜ì ì¸ ëŒ€í™”ë‚˜ ì¸ì‚¬
   - ì˜ˆ: "ì•ˆë…•í•˜ì„¸ìš”", "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ë„¤ìš”", "ê³ ë§ˆì›Œìš”", "ì˜í–ˆì–´ìš”", "ì¢‹ì€ í•˜ë£¨ ë³´ë‚´"

ì¶”ê°€ ì •ë³´:
- confidence: ì‘ë‹µ ìœ í˜• íŒŒì•… ì‹ ë¢°ë„ (0.0-1.0)
- entities: ì¶”ì¶œëœ ì—”í‹°í‹° (ëª¨ë“  ê´€ë ¨ ì •ë³´ í¬í•¨)
- reasoning: ì‘ë‹µ ìœ í˜• ì„ íƒ ê·¼ê±°

**ì—”í‹°í‹° ì¶”ì¶œ ì˜ˆì‹œ**:
- "ê°•ë‚¨ì—ì„œ ì¶”ë¦¬ í…Œë§ˆë¡œ ì¶”ì²œí•´ì¤˜" â†’ {{"preferred_regions": ["ê°•ë‚¨"], "preferred_themes": ["ì¶”ë¦¬"]}}
- "ê³µí¬ í…Œë§ˆëŠ” ì ˆëŒ€ ì•ˆë¼" â†’ {{"excluded_themes": ["ê³µí¬"]}}
- "4ëª…ì´ í•  ìˆ˜ ìˆëŠ” ê±°" â†’ {{"preferred_group_size": 4}}
- "ë‚¨ìì¹œêµ¬ë‘ ê°•ë‚¨ì—ì„œ ë°©íƒˆì¶œí• ê±´ë°" â†’ {{"preferred_group_size": 2, "preferred_regions": ["ê°•ë‚¨"]}}
- "ê°€ê²©ì€ 20000ì›ëŒ€" â†’ {{"price_min": 20000, "price_max": 30000}}
- "ìµœëŒ€ 3ë§Œì›ê¹Œì§€" â†’ {{"price_max": 30000}}
- "ìµœì†Œ 2ë§Œì› ì´ìƒ" â†’ {{"price_min": 20000}}
- "ë‚˜ ì™„ì „ ë°©ë¦°ì´ì•¼" â†’ {{"experience_level": "ë°©ë¦°ì´"}}
- "ë‚˜ëŠ” ì´ˆë³´ìì•¼" â†’ {{"experience_level": "ë°©ìƒì•„"}}
- "í”¼ìë‚˜ ì¹˜í‚¨ ê´€ë ¨ëœ í…Œë§ˆë¡œ ë°©íƒˆì¶œ ìˆì–´?" â†’ {{"keywords": "í”¼ì,ì¹˜í‚¨"}}

**ê²½í—˜ ë ˆë²¨ ë§¤í•‘**:
- "ë°©ìƒì•„", "ì´ˆë³´ì", "ì²˜ìŒ", "ì‹ ì…" â†’ "ë°©ìƒì•„"
- "ë°©ë¦°ì´", "ì¡°ê¸ˆ í•´ë´¤ì–´", "ê¸°ë³¸ì€ ì•Œì•„" â†’ "ë°©ë¦°ì´"  
- "ë°©ì†Œë…„", "ì¤‘ê¸‰ì", "ì–´ëŠì •ë„ í•´ë´¤ì–´" â†’ "ë°©ì†Œë…„"
- "ë°©ì–´ë¥¸", "ê³ ê¸‰ì", "ë§ì´ í•´ë´¤ì–´" â†’ "ë°©ì–´ë¥¸"
- "ë°©ì‹ ", "ì „ë¬¸ê°€", "ê³ ì¸ë¬¼" â†’ "ë°©ì‹ "
- "ë°©ì¥ë¡œ", "ìµœê³ ìˆ˜", "ë§ˆìŠ¤í„°" â†’ "ë°©ì¥ë¡œ"

**ì¤‘ìš”**: ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•íƒœë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ```json```ì´ë‚˜ ë‹¤ë¥¸ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.

JSON ì‘ë‹µ:
"""
        
        # LangChain ë°©ì‹ìœ¼ë¡œ í˜¸ì¶œ (í† í° ì‚¬ìš©ëŸ‰ í¬í•¨)
        start_time = time.time()
        response_text, token_usage = await llm.generate_with_messages_and_usage([HumanMessage(content=prompt)])
        response_time = (time.time() - start_time) * 1000
        
        # ì‹¤ì œ í† í° ì‚¬ìš©ëŸ‰ ê¸°ë°˜ ë¹„ìš© ê³„ì‚°
        prompt_tokens = token_usage.get('prompt_tokens', 0)
        completion_tokens = token_usage.get('completion_tokens', 0)
        
        # GPT-4o-mini ê°€ê²© (2025ë…„ 9ì›” 20ì¼ ê¸°ì¤€)
        # cf. https://platform.openai.com/docs/pricing
        input_cost = (prompt_tokens / 1000000) * 0.15  # $0.15 per 1M tokens
        output_cost = (completion_tokens / 1000000) * 0.60  # $0.60 per 1M tokens
        total_cost = input_cost + output_cost
        
        # í•œêµ­ ì›í™” í™˜ìœ¨ ê³„ì‚° (1 USD = 1500 KRW)
        total_cost_krw = total_cost * 1500
        total_tokens = prompt_tokens + completion_tokens
        logger.info(f"Intent ë¶„ì„ ë¹„ìš©: ${total_cost:.6f} (â‚©{total_cost_krw:.2f}) - ì‹¤ì œ í† í°: {total_tokens} (ì…ë ¥: {prompt_tokens}, ì¶œë ¥: {completion_tokens})")
        
        # API í˜¸ì¶œ ì¶”ì 
        track_api_call(
            service="openai",
            endpoint="analyze_intent", 
            status_code=200,
            duration_seconds=response_time / 1000,
            model="gpt-4o-mini",
            cost_usd=total_cost
        )
        
        # ì‘ë‹µ ì •ë¦¬
        response_text = response_text.strip()
        
        # JSON íŒŒì‹±
        try:
            intent_data = json.loads(response_text)
            intent_data.setdefault("timestamp", now_korea_iso())
            return intent_data
        except json.JSONDecodeError as e:
            logger.warning(f"LLM response JSON parsing failed: {e}")
            logger.warning(f"Response text: {response_text}")
            raise Exception("JSON parsing failed")
        
    except Exception as e:
        logger.error(f"LLM intent analysis error: {e}")
        # AI API ê´€ë ¨ ì—ëŸ¬ì¸ì§€ í™•ì¸
        if any(keyword in str(e).lower() for keyword in ["openai", "api", "llm", "model", "gpt", "claude", "gemini"]):
            raise CustomError("AI_API_CALL_ERROR", "AI API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        else:
            raise CustomError("CHATBOT_ERROR", "ì±—ë´‡ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

async def _analyze_intent_pattern_fallback(user_message: str) -> Dict[str, Any]:
    """DB ê¸°ë°˜ íŒ¨í„´ ë§¤ì¹­ fallback"""
    message = user_message.lower().strip()
    
    # DBì—ì„œ ì˜ë„ íŒ¨í„´ ì¡°íšŒ
    intent_patterns = await _get_intent_patterns()
    
    best_match = None
    best_confidence = 0.0
    
    # ê° ì˜ë„ë³„ íŒ¨í„´ ë§¤ì¹­
    for intent_name, patterns in intent_patterns.items():
        for pattern_data in patterns:
            pattern = pattern_data['pattern']
            confidence = pattern_data['confidence']
            
            if pattern in message:
                if confidence > best_confidence:
                    best_confidence = confidence
                    best_match = {
                        "intent": intent_name,
                        "confidence": confidence,
                        "reasoning": f"Pattern fallback: '{pattern}'",
                        "method": "pattern_matching"
                    }
    
    # ë§¤ì¹­ëœ ì˜ë„ê°€ ìˆìœ¼ë©´ ë°˜í™˜
    if best_match:
        return best_match
    
    # ê¸°ë³¸ê°’: ì¼ë°˜ ëŒ€í™”
    return {
        "intent": "general_chat",
        "confidence": 0.3,
        "reasoning": "No pattern matched - fallback to general chat",
        "method": "fallback_default"
    }

async def _get_intent_patterns() -> Dict[str, List[Dict]]:
    """ì˜ë„ íŒ¨í„´ ì¡°íšŒ (ë¡œê¹… + ì˜ˆì™¸ ì²˜ë¦¬)"""
    try:
        patterns = await get_intent_patterns_from_db()
        logger.info(f"Intent patterns loaded successfully: {len(patterns)} intents")
        return patterns
    except Exception as e:
        logger.error(f"Failed to fetch intent patterns: {e}")
        # Fallback ë°ì´í„° ë°˜í™˜
        fallback_patterns = {
            "recommendation": [
                {"pattern": "ì¶”ì²œ", "confidence": 1.0},
                {"pattern": "ì°¾ì•„", "confidence": 0.9}
            ]
        }
        logger.warning(f"Using fallback intent patterns: {fallback_patterns}")
        return fallback_patterns

